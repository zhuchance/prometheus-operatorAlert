2020/01/14 18:07:56.941 [I] [asm_amd64.s:1337] http server Running on http://:8080
2020/01/14 18:11:40.153 [D] [server.go:2774] 127.0.0.1 - - [14/Jan/2020 06:11:40] "POTS /graylog2/dingding HTTP/1.1 200 0" 0.000000  curl/7.65.3

2020/01/14 18:12:01.259 [D] [server.go:2774] 127.0.0.1 - - [14/Jan/2020 06:12:01] "POTS /graylog2/dingding HTTP/1.1 200 0" 0.000000  curl/7.65.3

2020/01/14 18:12:15.397 [I] [value.go:447] [1578996735397445800] {"check_result":{"result_description":"Dummy alert to test notifications","triggered_condition":{"id":"6ea4597b-49d2-4146-86b9-6566a22b15f7","type":"dummy","created_at":"2020-01-13T23:34:51.674Z","creator_user_id":"admin","title":"Test Alert","parameters":{}},"triggered_at":"2020-01-13T23:34:51.675Z","triggered":true,"matching_messages":[]},"stream":{"creator_user_id":"admin","outputs":[],"description":"Õ¯¬Á…Ë±∏»’÷æ","created_at":"2020-01-09T08:12:44.094Z","rules":[{"field":"Down","stream_id":"5e16e07c1935de48a9553389","description":"forwarding","id":"5e183ccc1935de48a956ad3f","type":1,"inverted":true,"value":"Down"}],"alert_conditions":[],"title":"Õ¯¬Á…Ë±∏»’÷æ","content_pack":null,"is_default_stream":false,"index_set_id":"5e16e02c1935de48a955332e","matching_type":"OR","remove_matches_from_default_stream":false,"disabled":false,"id":"5e16e07c1935de48a9553389"}}
2020/01/14 18:12:15.419 [I] [graylog2.go:103] [1578996735397445800] [dingding] {"msgtype":"markdown","markdown":{"title":"PrometheusAlertÂëäË≠¶‰ø°ÊÅØ","text":"## [PrometheusAlertGraylog2ÂëäË≠¶‰ø°ÊÅØ](http://graylog.org)\n\n#### Dummy alert to test notifications\n\n![PrometheusAlert](https://raw.githubusercontent.com/feiyu563/PrometheusAlert/master/doc/alert-center.png)"},"at":{"atMobiles":["15395105573"],"isAtAll":true}}

2020/01/14 18:12:15.556 [I] [graylog2.go:103] [1578996735397445800] [dingding] {"errcode":300001,"errmsg":"token is not exist"}
2020/01/14 18:12:15.557 [I] [graylog2.go:105] [1578996735397445800] [weixin] ‰ºÅ‰∏öÂæÆ‰ø°Êé•Âè£Êú™ÈÖçÁΩÆÊú™ÂºÄÂêØÁä∂ÊÄÅ,ËØ∑ÂÖàÈÖçÁΩÆopen-weixin‰∏∫1
2020/01/14 18:12:15.557 [I] [value.go:447] [1578996735397445800] ÂëäË≠¶Ê∂àÊÅØÂèëÈÄÅÂÆåÊàê.
2020/01/14 18:12:15.557 [D] [server.go:2774] 127.0.0.1 - - [14/Jan/2020 06:12:15] "POST /graylog2/dingding HTTP/1.1 200 0" 0.160426  curl/7.65.3

2020/01/14 18:12:39.995 [I] [value.go:447] [1578996759995188200] {"check_result":{"result_description":"Stream received messages matching <message:\"DOWN\"> (Current grace time: 1 minutes)","triggered_condition":{"id":"a0d239d2-6934-46cd-896d-99ad469a63be","type":"field_content_value","created_at":"2020-01-10T08:35:55.389Z","creator_user_id":"admin","title":"Õ¯¬Á…Ë±∏»’÷æ","parameters":{"backlog":1,"repeat_notifications":false,"field":"message","query":"*","grace":1,"value":"DOWN"}},"triggered_at":"2020-01-12T06:50:03.035Z","triggered":true,"matching_messages":[{"index":"2_3","message":"Jan 12 2020 06:49:44 E024-E025 %%01IFPDT/4/IF_STATE(l)[10680]:Interface GigabitEthernet1/0/15 has turned into DOWN state.","timestamp":"2020-01-12T06:49:44.942Z","fields":{"level":4,"full_message":"<188>Jan 12 2020 06:49:44 E010-E011 %%01IFPDT/4/IF_STATE(l)[10680]:Interface GigabitEthernet1/0/15 has turned into DOWN state.","gl2_remote_ip":"10.254.1.250","gl2_remote_port":38514,"gl2_source_node":"eb6b6cdc-9c09-42bd-b872-320f6f853caf","gl2_source_input":"5e15a0c21935de2be3933599","facility":"local7"},"id":"b838e101-3507-11ea-a01d-525400cf7ad1","source":"10.254.1.250","stream_ids":["5e16e07c1935de48a9553389","000000000000000000000001"]}]},"stream":{"creator_user_id":"admin","outputs":[],"description":"Õ¯¬Á…Ë±∏»’÷æ","created_at":"2020-01-09T08:12:44.094Z","rules":[{"field":"Down","stream_id":"5e16e07c1935de48a9553389","description":"forwarding","id":"5e183ccc1935de48a956ad3f","type":1,"inverted":true,"value":"Down"}],"alert_conditions":[{"creator_user_id":"admin","created_at":"2020-01-10T08:35:55.389Z","id":"a0d239d2-6934-46cd-896d-99ad469a63be","type":"field_content_value","title":"Õ¯¬Á…Ë±∏»’÷æ","parameters":{"backlog":1,"repeat_notifications":false,"field":"message","query":"*","grace":1,"value":"DOWN"}}],"title":"Õ¯¬Á…Ë±∏»’÷æ","content_pack":null,"is_default_stream":false,"index_set_id":"5e16e02c1935de48a955332e","matching_type":"OR","remove_matches_from_default_stream":false,"disabled":false,"id":"5e16e07c1935de48a9553389"}}
2020/01/14 18:12:51.089 [I] [graylog2.go:115] [1578996759995188200] [dingding] {"msgtype":"markdown","markdown":{"title":"PrometheusAlertÂëäË≠¶‰ø°ÊÅØ","text":"## [PrometheusAlertGraylog2ÂëäË≠¶‰ø°ÊÅØ](http://graylog.org)\n\n#### Stream received messages matching \u003cmessage:\"DOWN\"\u003e (Current grace time: 1 minutes)\n\n###### ÂëäË≠¶Á¥¢ÂºïÔºö2_3\n\n###### ÂºÄÂßãÊó∂Èó¥Ôºö2020-01-12T06:49:44.942Z \n\n###### ÂëäË≠¶‰∏ªÊú∫Ôºö10.254.1.250:0\n\n##### Jan 12 2020 06:49:44 E024-E025 %%01IFPDT/4/IF_STATE(l)[10680]:Interface GigabitEthernet1/0/15 has turned into DOWN state.\n\n![PrometheusAlert](https://raw.githubusercontent.com/feiyu563/PrometheusAlert/master/doc/alert-center.png)"},"at":{"atMobiles":["15395105573"],"isAtAll":true}}

2020/01/14 18:12:51.156 [I] [graylog2.go:115] [1578996759995188200] [dingding] {"errcode":300001,"errmsg":"token is not exist"}
2020/01/14 18:12:51.159 [I] [value.go:447] [1578996759995188200] ÂëäË≠¶Ê∂àÊÅØÂèëÈÄÅÂÆåÊàê.
2020/01/14 18:12:51.160 [D] [server.go:2774] 127.0.0.1 - - [14/Jan/2020 06:12:39] "POST /graylog2/dingding HTTP/1.1 200 0" 11.165693  curl/7.65.3

2020/05/25 18:10:03.837 [I] [asm_amd64.s:1373]  http server Running on http://:8080
2020/08/06 19:46:17.940 [I] [asm_amd64.s:1373]  http server Running on http://:8080
2021/04/02 17:31:39.291 [I] [asm_amd64.s:1371]  http server Running on http://:8080
2021/04/02 17:32:07.584 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     6.6752ms|   match|[44m GET     [0m /     r:/
2021/04/02 17:32:07.664 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    20.9392ms|   match|[44m GET     [0m /static/css/bootstrap.min.css
2021/04/02 17:32:07.679 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    34.7771ms|   match|[44m GET     [0m /static/css/docs.css
2021/04/02 17:32:07.728 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    13.9544ms|   match|[44m GET     [0m /static/img/prometheus-ico.png
2021/04/02 17:32:07.792 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    79.3601ms|   match|[44m GET     [0m /static/js/bootstrap.min.js
2021/04/02 17:32:07.901 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   189.9611ms|   match|[44m GET     [0m /static/js/jquery-3.3.1.min.js
2021/04/02 17:32:07.911 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   184.3291ms|   match|[44m GET     [0m /static/img/it.png
2021/04/02 17:32:07.920 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   193.5941ms|   match|[44m GET     [0m /static/img/wx.png
2021/04/02 17:32:10.099 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|      2.143ms|   match|[44m GET     [0m /     r:/
2021/04/02 17:32:10.592 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|           0s|   match|[44m GET     [0m /static/img/prometheus-ico.png
2021/04/02 17:33:24.911 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     4.3805ms|   match|[44m GET     [0m /     r:/
2021/04/02 17:33:26.963 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     2.5143ms|   match|[44m GET     [0m /test   r:/test
2021/04/02 17:33:29.793 [I] [default.go:114]  [1617356009793291600] [dingding] {"msgtype":"markdown","markdown":{"title":"PrometheusAlert","text":"## [PrometheusAlert](https://github.com/feiyu563/PrometheusAlert)\n\n#### ÊµãËØïÂëäË≠¶\n\n###### ÂëäË≠¶Á∫ßÂà´ÔºöÊµãËØï\n\n##### PrometheusAlert\n\n![PrometheusAlert](https://raw.githubusercontent.com/feiyu563/PrometheusAlert/master/doc/alert-center.png)"},"at":{"atMobiles":["15395105573"],"isAtAll":true}}

2021/04/02 17:33:30.504 [I] [default.go:114]  [1617356009793291600] [dingding] 
{"status":1111,"wait":5,"source":"x5","punish":"deny","uuid":"2516f9d3353f5626280007c50149bca7","errcode": 130101,"errmsg": "send too fast, exceed 20 times per minute"}
2021/04/02 17:33:30.506 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   714.2582ms|   match|[46m POST    [0m /alerttest   r:/alerttest
2021/04/02 17:33:32.763 [I] [default.go:110]  [1617356012759715000] [weixin] {"msgtype":"markdown","markdown":{"content":"[PrometheusAlert](https://github.com/feiyu563/PrometheusAlert)\n\u003e**ÊµãËØïÂëäË≠¶**\n\u003e`ÂëäË≠¶Á∫ßÂà´:`ÊµãËØï\n**PrometheusAlert**"}}

2021/04/02 17:33:33.176 [I] [default.go:110]  [1617356012759715000] [weixin] {"errcode":0,"errmsg":"ok"}
2021/04/02 17:33:33.178 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   420.2564ms|   match|[46m POST    [0m /alerttest   r:/alerttest
2021/04/02 17:33:47.262 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    16.5617ms|   match|[44m GET     [0m /static/css/bootstrap.min.css.map
2021/04/02 17:33:50.113 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    27.9161ms|   match|[44m GET     [0m /static/fonts/glyphicons-halflings-regular.woff2
2021/04/02 17:34:09.704 [I] [default.go:148]  [1617356048378196400] [email] email send ok to 18120100305@189.cn
2021/04/02 17:34:09.706 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   1.3278886s|   match|[46m POST    [0m /alerttest   r:/alerttest
2021/04/02 18:00:52.990 [I] [asm_amd64.s:1371]  http server Running on http://:8080
2021/04/02 18:00:53.136 [D] [server.go:2887]  |    10.192.0.51|[42m 200 [0m|    10.5969ms|   match|[44m GET     [0m /     r:/
2021/04/02 18:00:53.216 [D] [server.go:2887]  |    10.192.0.51|[42m 200 [0m|     6.1898ms|   match|[44m GET     [0m /static/css/bootstrap.min.css
2021/04/02 18:00:53.217 [D] [server.go:2887]  |    10.192.0.51|[42m 200 [0m|     3.9791ms|   match|[44m GET     [0m /static/css/docs.css
2021/04/02 18:00:53.287 [D] [server.go:2887]  |    10.192.0.51|[42m 200 [0m|     2.5547ms|   match|[44m GET     [0m /static/js/jquery-3.3.1.min.js
2021/04/02 18:00:53.321 [D] [server.go:2887]  |    10.192.0.51|[42m 200 [0m|    35.0994ms|   match|[44m GET     [0m /static/js/bootstrap.min.js
2021/04/02 18:00:53.324 [D] [server.go:2887]  |    10.192.0.51|[42m 200 [0m|    39.5424ms|   match|[44m GET     [0m /static/img/prometheus-ico.png
2021/04/02 18:00:53.332 [D] [server.go:2887]  |    10.192.0.51|[42m 200 [0m|    45.6659ms|   match|[44m GET     [0m /static/img/it.png
2021/04/02 18:00:53.333 [D] [server.go:2887]  |    10.192.0.51|[42m 200 [0m|    46.2083ms|   match|[44m GET     [0m /static/img/wx.png
2021/04/02 18:00:53.422 [D] [server.go:2887]  |    10.192.0.51|[42m 200 [0m|     9.7005ms|   match|[44m GET     [0m /static/css/bootstrap.min.css.map
2021/04/02 18:00:54.770 [D] [server.go:2887]  |    10.192.0.51|[42m 200 [0m|     1.0844ms|   match|[44m GET     [0m /static/img/prometheus-ico.png
2021/04/02 18:00:58.746 [D] [server.go:2887]  |    10.192.0.51|[42m 200 [0m|     3.2213ms|   match|[44m GET     [0m /test   r:/test
2021/04/02 18:00:58.977 [D] [server.go:2887]  |    10.192.0.51|[42m 200 [0m|     1.3718ms|   match|[44m GET     [0m /static/css/bootstrap.min.css.map
2021/04/02 18:01:01.507 [D] [server.go:2887]  |    10.192.0.51|[42m 200 [0m|     3.2728ms|   match|[44m GET     [0m /static/fonts/glyphicons-halflings-regular.woff2
2021/04/02 18:01:04.033 [I] [default.go:110]  [1617357664032125600] [weixin] {"msgtype":"markdown","markdown":{"content":"[PrometheusAlert](https://github.com/feiyu563/PrometheusAlert)\n\u003e**ÊµãËØïÂëäË≠¶**\n\u003e`ÂëäË≠¶Á∫ßÂà´:`ÊµãËØï\n**PrometheusAlert**"}}

2021/04/02 18:01:04.493 [I] [default.go:110]  [1617357664032125600] [weixin] {"errcode":0,"errmsg":"ok"}
2021/04/02 18:01:04.494 [D] [server.go:2887]  |    10.192.0.51|[42m 200 [0m|    467.039ms|   match|[46m POST    [0m /alerttest   r:/alerttest
2021/04/06 16:56:31.275 [I] [asm_amd64.s:1371]  http server Running on http://:8080
2021/04/06 16:56:31.282 [C] [asm_amd64.s:1371]  ListenAndServe:  listen tcp :8080: bind: Only one usage of each socket address (protocol/network address/port) is normally permitted.
2021/04/06 16:56:41.925 [I] [asm_amd64.s:1371]  http server Running on http://:8080
2021/04/06 16:56:53.363 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     9.0522ms|   match|[44m GET     [0m /     r:/
2021/04/06 16:56:55.458 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     3.0659ms|   match|[44m GET     [0m /test   r:/test
2021/04/06 16:56:58.894 [I] [default.go:118]  [1617699418894571400] [feishu] È£û‰π¶Êé•Âè£Êú™ÈÖçÁΩÆÊú™ÂºÄÂêØÁä∂ÊÄÅ,ËØ∑ÂÖàÈÖçÁΩÆopen-feishu‰∏∫1
2021/04/06 16:56:58.896 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     2.5465ms|   match|[46m POST    [0m /alerttest   r:/alerttest
2021/04/06 16:57:33.942 [I] [default.go:118]  [1617699453942082000] [feishu] È£û‰π¶Êé•Âè£Êú™ÈÖçÁΩÆÊú™ÂºÄÂêØÁä∂ÊÄÅ,ËØ∑ÂÖàÈÖçÁΩÆopen-feishu‰∏∫1
2021/04/06 16:57:33.943 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|      826.8¬µs|   match|[46m POST    [0m /alerttest   r:/alerttest
2021/04/06 16:58:31.207 [I] [asm_amd64.s:1371]  http server Running on http://:8080
2021/04/06 16:58:34.817 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     5.5357ms|   match|[44m GET     [0m /test   r:/test
2021/04/06 16:58:36.356 [I] [default.go:110]  [1617699516355344300] [weixin] {"msgtype":"markdown","markdown":{"content":"[PrometheusAlert](https://github.com/feiyu563/PrometheusAlert)\n\u003e**ÊµãËØïÂëäË≠¶**\n\u003e`ÂëäË≠¶Á∫ßÂà´:`ÊµãËØï\n**PrometheusAlert**"}}

2021/04/06 16:58:36.450 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    15.9794ms|   match|[44m GET     [0m /static/img/prometheus-ico.png
2021/04/06 16:58:37.819 [I] [default.go:110]  [1617699516355344300] [weixin] {"errcode":0,"errmsg":"ok"}
2021/04/06 16:58:37.820 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   1.4654711s|   match|[46m POST    [0m /alerttest   r:/alerttest
2021/04/06 16:59:06.280 [I] [feishu.go:32]  [1617699546279801700] [feishu] {"title":"PrometheusAlert","text":"[PrometheusAlert](https://github.com/feiyu563/PrometheusAlert)\n\nÊµãËØïÂëäË≠¶\n\nÂëäË≠¶Á∫ßÂà´ÔºöÊµãËØï\n\nPrometheusAlert\n\n![PrometheusAlert](https://raw.githubusercontent.com/feiyu563/PrometheusAlert/master/doc/alert-center.png)"}

2021/04/06 16:59:06.937 [I] [feishu.go:32]  [1617699546279801700] [feishu] <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<title>404 Not Found</title>
<h1>Not Found</h1>
<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>

2021/04/06 16:59:06.938 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    660.397ms|   match|[46m POST    [0m /alerttest   r:/alerttest
2021/04/06 17:00:52.878 [I] [feishu.go:32]  [1617699652878760700] [feishu] {"title":"PrometheusAlert","text":"[PrometheusAlert](https://github.com/feiyu563/PrometheusAlert)\n\nÊµãËØïÂëäË≠¶\n\nÂëäË≠¶Á∫ßÂà´ÔºöÊµãËØï\n\nPrometheusAlert\n\n![PrometheusAlert](https://raw.githubusercontent.com/feiyu563/PrometheusAlert/master/doc/alert-center.png)"}

2021/04/06 17:00:56.834 [I] [feishu.go:32]  [1617699656834951900] [feishu] {"title":"PrometheusAlert","text":"[PrometheusAlert](https://github.com/feiyu563/PrometheusAlert)\n\nÊµãËØïÂëäË≠¶\n\nÂëäË≠¶Á∫ßÂà´ÔºöÊµãËØï\n\nPrometheusAlert\n\n![PrometheusAlert](https://raw.githubusercontent.com/feiyu563/PrometheusAlert/master/doc/alert-center.png)"}

2021/04/21 15:00:07.591 [I] [asm_amd64.s:1371]  http server Running on http://:8080
2021/04/21 15:00:14.057 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    10.7544ms|   match|[44m GET     [0m /     r:/
2021/04/21 15:00:14.152 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    16.1083ms|   match|[44m GET     [0m /static/img/prometheus-ico.png
2021/04/21 15:00:14.163 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    17.8204ms|   match|[44m GET     [0m /static/img/it.png
2021/04/21 15:00:14.175 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    24.5139ms|   match|[44m GET     [0m /static/img/wx.png
2021/04/21 15:00:14.288 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   132.3602ms|   match|[44m GET     [0m /static/js/jquery-3.3.1.min.js
2021/04/21 15:00:14.374 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   214.0099ms|   match|[44m GET     [0m /static/js/bootstrap.min.js
2021/04/21 15:00:15.934 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     3.2311ms|   match|[44m GET     [0m /test   r:/test
2021/04/21 15:00:16.959 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|      16.71ms|   match|[44m GET     [0m /static/fonts/glyphicons-halflings-regular.woff2
2021/04/21 15:00:18.052 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   170.9517ms|   match|[44m GET     [0m /template   r:/template
2021/04/21 15:00:23.562 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|      6.904ms|   match|[44m GET     [0m /template/edit   r:/template/edit
2021/04/21 15:01:36.270 [D] [value.go:476]  [1618988496270017700] {	"receiver": "prometheus-alert-center",	"status": "firing",	"alerts": [{		"status": "firing",		"labels": {			"alertname": "TargetDown",			"index": "1",			"instance": "example-1",			"job": "example",			"level": "2",			"service": "example"		},		"annotations": {			"description": "target was down! example dev /example-1 was down for more than 120s.",			"level": "2",			"timestamp": "2020-05-21 02:58:07.829 +0000 UTC"		},		"startsAt": "2020-05-21T02:58:07.830216179Z",		"endsAt": "0001-01-01T00:00:00Z",		"generatorURL": "https://prometheus-alert-center/graph?g0.expr=up%7Bjob%21%3D%22kubernetes-pods%22%2Cjob%21%3D%22kubernetes-service-endpoints%22%7D+%21%3D+1\u0026g0.tab=1",		"fingerprint": "e2a5025853d4da64"	}],	"groupLabels": {		"instance": "example-1"	},	"commonLabels": {		"alertname": "TargetDown",		"index": "1",		"instance": "example-1",		"job": "example",		"level": "2",		"service": "example"	},	"commonAnnotations": {		"description": "target was down! example dev /example-1 was down for more than 120s.",		"level": "2",		"timestamp": "2020-05-21 02:58:07.829 +0000 UTC"	},	"externalURL": "https://prometheus-alert-center",	"version": "4",	"groupKey": "{}/{job=~\"^(?:.*)$\"}:{instance=\"example-1\"}"}
2021/04/21 15:01:36.274 [I] [prometheusalert.go:83]  [1618988496270017700] [dingding] {"msgtype":"markdown","markdown":{"title":"PrometheusAlertÂëäË≠¶Ê∂àÊÅØ","text":"\r\n\r\n## [PrometheusÂëäË≠¶‰ø°ÊÅØ](https://prometheus-alert-center/graph?g0.expr=up%7Bjob%21%3D%22kubernetes-pods%22%2Cjob%21%3D%22kubernetes-service-endpoints%22%7D+%21%3D+1\u0026g0.tab=1)\r\n#### [TargetDown](https://prometheus-alert-center)\r\n###### ÂëäË≠¶Á∫ßÂà´Ôºö2\r\n###### ÂºÄÂßãÊó∂Èó¥Ôºö2020-05-21T02:58:07.830216179Z\r\n###### ÁªìÊùüÊó∂Èó¥Ôºö0001-01-01T00:00:00Z\r\n###### ÊïÖÈöú‰∏ªÊú∫IPÔºöexample-1\r\n##### target was down! example dev /example-1 was down for more than 120s.\r\n![Prometheus](https://raw.githubusercontent.com/feiyu563/PrometheusAlert/master/doc/alert-center.png)\r\n\r\n"},"at":{"atMobiles":["15395105573"],"isAtAll":true}}

2021/04/21 15:01:36.307 [I] [prometheusalert.go:83]  [1618988496270017700] [dingding] {"msg":"Êìç‰ΩúÊàêÂäü","code":200}
2021/04/21 15:01:36.308 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    39.6845ms|   match|[46m POST    [0m /prometheusalert   r:/prometheusalert
2021/04/21 15:02:30.088 [D] [value.go:476]  [1618988550088032300] {	"receiver": "prometheus-alert-center",	"status": "firing",	"alerts": [{		"status": "firing",		"labels": {			"alertname": "TargetDown",			"index": "1",			"instance": "example-1",			"job": "example",			"level": "2",			"service": "example"		},		"annotations": {			"description": "target was down! example dev /example-1 was down for more than 120s.",			"level": "2",			"timestamp": "2020-05-21 02:58:07.829 +0000 UTC"		},		"startsAt": "2020-05-21T02:58:07.830216179Z",		"endsAt": "0001-01-01T00:00:00Z",		"generatorURL": "https://prometheus-alert-center/graph?g0.expr=up%7Bjob%21%3D%22kubernetes-pods%22%2Cjob%21%3D%22kubernetes-service-endpoints%22%7D+%21%3D+1\u0026g0.tab=1",		"fingerprint": "e2a5025853d4da64"	}],	"groupLabels": {		"instance": "example-1"	},	"commonLabels": {		"alertname": "TargetDown",		"index": "1",		"instance": "example-1",		"job": "example",		"level": "2",		"service": "example"	},	"commonAnnotations": {		"description": "target was down! example dev /example-1 was down for more than 120s.",		"level": "2",		"timestamp": "2020-05-21 02:58:07.829 +0000 UTC"	},	"externalURL": "https://prometheus-alert-center",	"version": "4",	"groupKey": "{}/{job=~\"^(?:.*)$\"}:{instance=\"example-1\"}"}
2021/04/21 15:02:30.091 [I] [prometheusalert.go:125]  [1618988550088032300] [tg] telegramÊú™ÈÖçÁΩÆÊú™ÂºÄÂêØÁä∂ÊÄÅ,ËØ∑ÂÖàÈÖçÁΩÆopen-tg‰∏∫1
2021/04/21 15:02:30.092 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|      8.837ms|   match|[46m POST    [0m /prometheusalert   r:/prometheusalert
2021/04/21 15:10:18.405 [D] [value.go:476]  [1618989018405463700] {	"receiver": "prometheus-alert-center",	"status": "firing",	"alerts": [{		"status": "firing",		"labels": {			"alertname": "TargetDown",			"index": "1",			"instance": "example-1",			"job": "example",			"level": "2",			"service": "example"		},		"annotations": {			"description": "target was down! example dev /example-1 was down for more than 120s.",			"level": "2",			"timestamp": "2020-05-21 02:58:07.829 +0000 UTC"		},		"startsAt": "2020-05-21T02:58:07.830216179Z",		"endsAt": "0001-01-01T00:00:00Z",		"generatorURL": "https://prometheus-alert-center/graph?g0.expr=up%7Bjob%21%3D%22kubernetes-pods%22%2Cjob%21%3D%22kubernetes-service-endpoints%22%7D+%21%3D+1\u0026g0.tab=1",		"fingerprint": "e2a5025853d4da64"	}],	"groupLabels": {		"instance": "example-1"	},	"commonLabels": {		"alertname": "TargetDown",		"index": "1",		"instance": "example-1",		"job": "example",		"level": "2",		"service": "example"	},	"commonAnnotations": {		"description": "target was down! example dev /example-1 was down for more than 120s.",		"level": "2",		"timestamp": "2020-05-21 02:58:07.829 +0000 UTC"	},	"externalURL": "https://prometheus-alert-center",	"version": "4",	"groupKey": "{}/{job=~\"^(?:.*)$\"}:{instance=\"example-1\"}"}
2021/04/21 15:10:18.407 [I] [prometheusalert.go:125]  [1618989018405463700] [tg] telegramÊú™ÈÖçÁΩÆÊú™ÂºÄÂêØÁä∂ÊÄÅ,ËØ∑ÂÖàÈÖçÁΩÆopen-tg‰∏∫1
2021/04/21 15:10:18.407 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     3.2773ms|   match|[46m POST    [0m /prometheusalert   r:/prometheusalert
2021/04/21 15:12:52.663 [D] [value.go:476]  [1618989172663125300] {	"receiver": "prometheus-alert-center",	"status": "firing",	"alerts": [{		"status": "firing",		"labels": {			"alertname": "TargetDown",			"index": "1",			"instance": "example-1",			"job": "example",			"level": "2",			"service": "example"		},		"annotations": {			"description": "target was down! example dev /example-1 was down for more than 120s.",			"level": "2",			"timestamp": "2020-05-21 02:58:07.829 +0000 UTC"		},		"startsAt": "2020-05-21T02:58:07.830216179Z",		"endsAt": "0001-01-01T00:00:00Z",		"generatorURL": "https://prometheus-alert-center/graph?g0.expr=up%7Bjob%21%3D%22kubernetes-pods%22%2Cjob%21%3D%22kubernetes-service-endpoints%22%7D+%21%3D+1\u0026g0.tab=1",		"fingerprint": "e2a5025853d4da64"	}],	"groupLabels": {		"instance": "example-1"	},	"commonLabels": {		"alertname": "TargetDown",		"index": "1",		"instance": "example-1",		"job": "example",		"level": "2",		"service": "example"	},	"commonAnnotations": {		"description": "target was down! example dev /example-1 was down for more than 120s.",		"level": "2",		"timestamp": "2020-05-21 02:58:07.829 +0000 UTC"	},	"externalURL": "https://prometheus-alert-center",	"version": "4",	"groupKey": "{}/{job=~\"^(?:.*)$\"}:{instance=\"example-1\"}"}
2021/04/21 15:12:52.664 [I] [prometheusalert.go:125]  [1618989172663125300] [tg] telegramÊú™ÈÖçÁΩÆÊú™ÂºÄÂêØÁä∂ÊÄÅ,ËØ∑ÂÖàÈÖçÁΩÆopen-tg‰∏∫1
2021/04/21 15:12:52.665 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     2.7393ms|   match|[46m POST    [0m /prometheusalert   r:/prometheusalert
2021/04/21 15:12:57.051 [I] [asm_amd64.s:1371]  http server Running on http://:8080
2021/04/21 15:12:59.214 [D] [value.go:476]  [1618989179214872300] {	"receiver": "prometheus-alert-center",	"status": "firing",	"alerts": [{		"status": "firing",		"labels": {			"alertname": "TargetDown",			"index": "1",			"instance": "example-1",			"job": "example",			"level": "2",			"service": "example"		},		"annotations": {			"description": "target was down! example dev /example-1 was down for more than 120s.",			"level": "2",			"timestamp": "2020-05-21 02:58:07.829 +0000 UTC"		},		"startsAt": "2020-05-21T02:58:07.830216179Z",		"endsAt": "0001-01-01T00:00:00Z",		"generatorURL": "https://prometheus-alert-center/graph?g0.expr=up%7Bjob%21%3D%22kubernetes-pods%22%2Cjob%21%3D%22kubernetes-service-endpoints%22%7D+%21%3D+1\u0026g0.tab=1",		"fingerprint": "e2a5025853d4da64"	}],	"groupLabels": {		"instance": "example-1"	},	"commonLabels": {		"alertname": "TargetDown",		"index": "1",		"instance": "example-1",		"job": "example",		"level": "2",		"service": "example"	},	"commonAnnotations": {		"description": "target was down! example dev /example-1 was down for more than 120s.",		"level": "2",		"timestamp": "2020-05-21 02:58:07.829 +0000 UTC"	},	"externalURL": "https://prometheus-alert-center",	"version": "4",	"groupKey": "{}/{job=~\"^(?:.*)$\"}:{instance=\"example-1\"}"}
2021/04/21 15:13:20.318 [E] [telegram.go:28]  [1618989179214872300] [tg] Post "https://api.telegram.org/botxxxxx/getMe": dial tcp 108.160.167.148:443: connectex: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond.
2021/04/21 15:13:20.319 [C] [panic.go:965]  the request url is  /prometheusalert
2021/04/21 15:13:20.320 [C] [panic.go:965]  Handler crashed with error runtime error: invalid memory address or nil pointer dereference
2021/04/21 15:13:20.321 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/panic.go:965
2021/04/21 15:13:20.322 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/panic.go:212
2021/04/21 15:13:20.322 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/signal_windows.go:239
2021/04/21 15:13:20.324 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/go-telegram-bot-api/telegram-bot-api/v5/bot.go:100
2021/04/21 15:13:20.324 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/go-telegram-bot-api/telegram-bot-api/v5/bot.go:319
2021/04/21 15:13:20.325 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/go-telegram-bot-api/telegram-bot-api/v5/bot.go:326
2021/04/21 15:13:20.327 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/controllers/telegram.go:33
2021/04/21 15:13:20.329 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/controllers/prometheusalert.go:125
2021/04/21 15:13:20.330 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/controllers/prometheusalert.go:57
2021/04/21 15:13:20.333 [C] [panic.go:965]  C:/Program Files/Go/src/reflect/value.go:476
2021/04/21 15:13:20.334 [C] [panic.go:965]  C:/Program Files/Go/src/reflect/value.go:337
2021/04/21 15:13:20.335 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/astaxie/beego/router.go:853
2021/04/21 15:13:20.335 [C] [panic.go:965]  C:/Program Files/Go/src/net/http/server.go:2887
2021/04/21 15:13:20.336 [C] [panic.go:965]  C:/Program Files/Go/src/net/http/server.go:1952
2021/04/21 15:13:20.337 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/asm_amd64.s:1371
2021/04/21 15:13:20.342 [server.go:3137]  [HTTP] http: superfluous response.WriteHeader call from github.com/astaxie/beego/context.(*Response).WriteHeader (context.go:230)
2021/04/21 15:13:34.789 [D] [value.go:476]  [1618989214789150100] {	"receiver": "prometheus-alert-center",	"status": "firing",	"alerts": [{		"status": "firing",		"labels": {			"alertname": "TargetDown",			"index": "1",			"instance": "example-1",			"job": "example",			"level": "2",			"service": "example"		},		"annotations": {			"description": "target was down! example dev /example-1 was down for more than 120s.",			"level": "2",			"timestamp": "2020-05-21 02:58:07.829 +0000 UTC"		},		"startsAt": "2020-05-21T02:58:07.830216179Z",		"endsAt": "0001-01-01T00:00:00Z",		"generatorURL": "https://prometheus-alert-center/graph?g0.expr=up%7Bjob%21%3D%22kubernetes-pods%22%2Cjob%21%3D%22kubernetes-service-endpoints%22%7D+%21%3D+1\u0026g0.tab=1",		"fingerprint": "e2a5025853d4da64"	}],	"groupLabels": {		"instance": "example-1"	},	"commonLabels": {		"alertname": "TargetDown",		"index": "1",		"instance": "example-1",		"job": "example",		"level": "2",		"service": "example"	},	"commonAnnotations": {		"description": "target was down! example dev /example-1 was down for more than 120s.",		"level": "2",		"timestamp": "2020-05-21 02:58:07.829 +0000 UTC"	},	"externalURL": "https://prometheus-alert-center",	"version": "4",	"groupKey": "{}/{job=~\"^(?:.*)$\"}:{instance=\"example-1\"}"}
2021/04/21 15:13:55.862 [E] [telegram.go:28]  [1618989214789150100] [tg] Post "https://api.telegram.org/botxxxxx/getMe": dial tcp 108.160.167.148:443: connectex: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond.
2021/04/21 15:14:16.303 [C] [panic.go:965]  the request url is  /prometheusalert
2021/04/21 15:14:09.961 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     3.4517ms|   match|[44m GET     [0m /     r:/
2021/04/21 15:14:16.304 [C] [panic.go:965]  Handler crashed with error runtime error: invalid memory address or nil pointer dereference
2021/04/21 15:14:16.308 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/panic.go:965
2021/04/21 15:14:16.309 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/panic.go:212
2021/04/21 15:14:16.310 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|  12.0663706s|   match|[44m GET     [0m /template/edit   r:/template/edit
2021/04/21 15:14:16.314 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/signal_windows.go:239
2021/04/21 15:14:16.319 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/go-telegram-bot-api/telegram-bot-api/v5/bot.go:100
2021/04/21 15:14:16.322 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/go-telegram-bot-api/telegram-bot-api/v5/bot.go:319
2021/04/21 15:14:16.325 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/go-telegram-bot-api/telegram-bot-api/v5/bot.go:326
2021/04/21 15:14:16.329 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/controllers/telegram.go:33
2021/04/21 15:14:16.327 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   4.7098409s|   match|[44m GET     [0m /template   r:/template
2021/04/21 15:14:16.330 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/controllers/prometheusalert.go:125
2021/04/21 15:14:16.332 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/controllers/prometheusalert.go:57
2021/04/21 15:14:16.337 [C] [panic.go:965]  C:/Program Files/Go/src/reflect/value.go:476
2021/04/21 15:14:16.338 [C] [panic.go:965]  C:/Program Files/Go/src/reflect/value.go:337
2021/04/21 15:14:16.340 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   4.0511703s|   match|[44m GET     [0m /template   r:/template
2021/04/21 15:14:16.340 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   3.9510763s|   match|[44m GET     [0m /template   r:/template
2021/04/21 15:14:16.343 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/astaxie/beego/router.go:853
2021/04/21 15:14:16.350 [C] [panic.go:965]  C:/Program Files/Go/src/net/http/server.go:2887
2021/04/21 15:14:16.352 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   3.8192812s|   match|[44m GET     [0m /template   r:/template
2021/04/21 15:14:16.352 [C] [panic.go:965]  C:/Program Files/Go/src/net/http/server.go:1952
2021/04/21 15:14:16.360 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/asm_amd64.s:1371
2021/04/21 15:14:16.351 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   3.6767451s|   match|[44m GET     [0m /template   r:/template
2021/04/21 15:14:16.362 [server.go:3137]  [HTTP] http: superfluous response.WriteHeader call from github.com/astaxie/beego/context.(*Response).WriteHeader (context.go:230)
2021/04/21 15:14:18.712 [I] [asm_amd64.s:1371]  http server Running on http://:8080
2021/04/21 15:14:27.199 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     4.5144ms|   match|[44m GET     [0m /template/add   r:/template/add
2021/04/21 15:15:30.771 [D] [value.go:476]  [1618989330771618500] {	"receiver": "prometheus-alert-center",	"status": "firing",	"alerts": [{		"status": "firing",		"labels": {			"alertname": "TargetDown",			"index": "1",			"instance": "example-1",			"job": "example",			"level": "2",			"service": "example"		},		"annotations": {			"description": "target was down! example dev /example-1 was down for more than 120s.",			"level": "2",			"timestamp": "2020-05-21 02:58:07.829 +0000 UTC"		},		"startsAt": "2020-05-21T02:58:07.830216179Z",		"endsAt": "0001-01-01T00:00:00Z",		"generatorURL": "https://prometheus-alert-center/graph?g0.expr=up%7Bjob%21%3D%22kubernetes-pods%22%2Cjob%21%3D%22kubernetes-service-endpoints%22%7D+%21%3D+1\u0026g0.tab=1",		"fingerprint": "e2a5025853d4da64"	}],	"groupLabels": {		"instance": "example-1"	},	"commonLabels": {		"alertname": "TargetDown",		"index": "1",		"instance": "example-1",		"job": "example",		"level": "2",		"service": "example"	},	"commonAnnotations": {		"description": "target was down! example dev /example-1 was down for more than 120s.",		"level": "2",		"timestamp": "2020-05-21 02:58:07.829 +0000 UTC"	},	"externalURL": "https://prometheus-alert-center",	"version": "4",	"groupKey": "{}/{job=~\"^(?:.*)$\"}:{instance=\"example-1\"}"}
2021/04/21 15:15:30.773 [E] [value.go:476]  [1618989330771618500] <QuerySeter> no row found
2021/04/21 15:15:51.880 [E] [telegram.go:28]  [1618989330771618500] [tg] Post "https://api.telegram.org/botxxxxx/getMe": dial tcp 108.160.167.148:443: connectex: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond.
2021/04/21 15:15:51.881 [C] [panic.go:965]  the request url is  /prometheusalert
2021/04/21 15:15:51.882 [C] [panic.go:965]  Handler crashed with error runtime error: invalid memory address or nil pointer dereference
2021/04/21 15:15:51.883 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/panic.go:965
2021/04/21 15:15:51.884 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/panic.go:212
2021/04/21 15:15:51.884 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/signal_windows.go:239
2021/04/21 15:15:51.885 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/go-telegram-bot-api/telegram-bot-api/v5/bot.go:100
2021/04/21 15:15:51.885 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/go-telegram-bot-api/telegram-bot-api/v5/bot.go:319
2021/04/21 15:15:51.886 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/go-telegram-bot-api/telegram-bot-api/v5/bot.go:326
2021/04/21 15:15:51.887 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/controllers/telegram.go:33
2021/04/21 15:15:51.888 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/controllers/prometheusalert.go:125
2021/04/21 15:15:51.889 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/controllers/prometheusalert.go:57
2021/04/21 15:15:51.894 [C] [panic.go:965]  C:/Program Files/Go/src/reflect/value.go:476
2021/04/21 15:15:51.899 [C] [panic.go:965]  C:/Program Files/Go/src/reflect/value.go:337
2021/04/21 15:15:51.900 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/astaxie/beego/router.go:853
2021/04/21 15:15:51.903 [C] [panic.go:965]  C:/Program Files/Go/src/net/http/server.go:2887
2021/04/21 15:15:51.904 [C] [panic.go:965]  C:/Program Files/Go/src/net/http/server.go:1952
2021/04/21 15:15:51.910 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/asm_amd64.s:1371
2021/04/21 15:15:51.914 [server.go:3137]  [HTTP] http: superfluous response.WriteHeader call from github.com/astaxie/beego/context.(*Response).WriteHeader (context.go:230)
2021/04/21 15:15:54.203 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     6.3325ms|   match|[44m GET     [0m /     r:/
2021/04/21 15:17:50.972 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     6.4115ms|   match|[44m GET     [0m /test   r:/test
2021/04/21 15:18:00.981 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     62.531ms|   match|[44m GET     [0m /template   r:/template
2021/04/21 15:18:31.092 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     5.5431ms|   match|[44m GET     [0m /template/edit   r:/template/edit
2021/04/21 15:19:42.607 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     9.9065ms|   match|[44m GET     [0m /template/edit   r:/template/edit
2021/04/21 17:24:27.029 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    20.6019ms|   match|[44m GET     [0m /     r:/
2021/04/21 17:24:29.292 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     5.6833ms|   match|[44m GET     [0m /test   r:/test
2021/04/21 17:24:31.324 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    19.9035ms|   match|[44m GET     [0m /template   r:/template
2021/04/21 17:24:35.180 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|      8.391ms|   match|[44m GET     [0m /template/edit   r:/template/edit
2021/04/21 17:35:01.551 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    21.8562ms|   match|[46m POST    [0m /template/addtpl   r:/template/addtpl
2021/04/21 17:35:03.412 [D] [value.go:476]  [1618997703412748600] {	"receiver": "webhook",	"status": "firing",	"alerts": [{		"status": "firing",		"labels": {			"alertname": "KubeStatefulSetReplicasMismatch",			"instance": "172.29.33.79:8443",			"job": "kube-state-metrics",			"namespace": "default",			"prometheus": "monitoring/k8s",			"severity": "warning",			"statefulset": "rd"		},		"annotations": {			"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",			"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"		},		"startsAt": "2021-04-02T09:00:05.095800493Z",		"endsAt": "0001-01-01T00:00:00Z",		"generatorURL": "http://prometheus-k8s-0:9090/graph?g0.expr=%28kube_statefulset_status_replicas_ready%7Bjob%3D%22kube-state-metrics%22%7D+%21%3D+kube_statefulset_status_replicas%7Bjob%3D%22kube-state-metrics%22%7D%29+and+%28changes%28kube_statefulset_status_replicas_updated%7Bjob%3D%22kube-state-metrics%22%7D%5B5m%5D%29+%3D%3D+0%29\u0026g0.tab=1",		"fingerprint": "1b3a1aba94e2a02f"	}],	"groupLabels": {		"alertname": "KubeStatefulSetReplicasMismatch"	},	"commonLabels": {		"alertname": "KubeStatefulSetReplicasMismatch",		"instance": "172.29.33.79:8443",		"job": "kube-state-metrics",		"namespace": "default",		"prometheus": "monitoring/k8s",		"severity": "warning",		"statefulset": "rd"	},	"commonAnnotations": {		"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",		"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"	},	"externalURL": "http://alertmanager-main-0:9093",	"version": "4",	"groupKey": "{}:{alertname=\"KubeStatefulSetReplicasMismatch\"}",	"truncatedAlerts": 0}
2021/04/21 17:35:03.425 [I] [prometheusalert.go:83]  [1618997703412748600] [dingding] {"msgtype":"markdown","markdown":{"title":"PrometheusAlertÂëäË≠¶Ê∂àÊÅØ","text":"\r\n\r\n [PrometheusÂëäË≠¶‰ø°ÊÅØ](http://prometheus-k8s-0:9090/graph?g0.expr=%28kube_statefulset_status_replicas_ready%7Bjob%3D%22kube-state-metrics%22%7D+%21%3D+kube_statefulset_status_replicas%7Bjob%3D%22kube-state-metrics%22%7D%29+and+%28changes%28kube_statefulset_status_replicas_updated%7Bjob%3D%22kube-state-metrics%22%7D%5B5m%5D%29+%3D%3D+0%29\u0026g0.tab=1)\r\n [KubeStatefulSetReplicasMismatch](http://alertmanager-main-0:9093)\r\n## ÂëäË≠¶Á∫ßÂà´Ôºö\u003cno value\u003e\r\n## ÂºÄÂßãÊó∂Èó¥Ôºö2021-04-02 17:00:05\r\n## ÁªìÊùüÊó∂Èó¥Ôºö0001-01-01 08:00:00\r\n## ÊïÖÈöú‰∏ªÊú∫IPÔºö172.29.33.79:8443\r\n# \u003cno value\u003e\r\n\r\n"},"at":{"atMobiles":["15395105573"],"isAtAll":true}}

2021/04/21 17:35:03.470 [I] [prometheusalert.go:83]  [1618997703412748600] [dingding] {"msg":"Êìç‰ΩúÊàêÂäü","code":200}
2021/04/21 17:35:03.470 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    58.1277ms|   match|[46m POST    [0m /prometheusalert   r:/prometheusalert
2021/04/21 17:35:54.185 [D] [value.go:476]  [1618997754185329400] {	"receiver": "webhook",	"status": "firing",	"alerts": [{		"status": "firing",		"labels": {			"alertname": "KubeStatefulSetReplicasMismatch",			"instance": "172.29.33.79:8443",			"job": "kube-state-metrics",			"namespace": "default",			"prometheus": "monitoring/k8s",			"severity": "warning",			"statefulset": "rd"		},		"annotations": {			"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",			"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"		},		"startsAt": "2021-04-02T09:00:05.095800493Z",		"endsAt": "0001-01-01T00:00:00Z",		"generatorURL": "http://prometheus-k8s-0:9090/graph?g0.expr=%28kube_statefulset_status_replicas_ready%7Bjob%3D%22kube-state-metrics%22%7D+%21%3D+kube_statefulset_status_replicas%7Bjob%3D%22kube-state-metrics%22%7D%29+and+%28changes%28kube_statefulset_status_replicas_updated%7Bjob%3D%22kube-state-metrics%22%7D%5B5m%5D%29+%3D%3D+0%29\u0026g0.tab=1",		"fingerprint": "1b3a1aba94e2a02f"	}],	"groupLabels": {		"alertname": "KubeStatefulSetReplicasMismatch"	},	"commonLabels": {		"alertname": "KubeStatefulSetReplicasMismatch",		"instance": "172.29.33.79:8443",		"job": "kube-state-metrics",		"namespace": "default",		"prometheus": "monitoring/k8s",		"severity": "warning",		"statefulset": "rd"	},	"commonAnnotations": {		"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",		"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"	},	"externalURL": "http://alertmanager-main-0:9093",	"version": "4",	"groupKey": "{}:{alertname=\"KubeStatefulSetReplicasMismatch\"}",	"truncatedAlerts": 0}
2021/04/21 17:35:56.689 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|  20.4037591s|   match|[46m POST    [0m /template/addtpl   r:/template/addtpl
2021/04/21 17:35:56.702 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   8.1935998s|   match|[46m POST    [0m /template/addtpl   r:/template/addtpl
2021/04/21 17:36:01.263 [I] [asm_amd64.s:1371]  http server Running on http://:8080
2021/04/21 17:36:08.564 [D] [value.go:476]  [1618997768564016800] {	"receiver": "webhook",	"status": "firing",	"alerts": [{		"status": "firing",		"labels": {			"alertname": "KubeStatefulSetReplicasMismatch",			"instance": "172.29.33.79:8443",			"job": "kube-state-metrics",			"namespace": "default",			"prometheus": "monitoring/k8s",			"severity": "warning",			"statefulset": "rd"		},		"annotations": {			"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",			"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"		},		"startsAt": "2021-04-02T09:00:05.095800493Z",		"endsAt": "0001-01-01T00:00:00Z",		"generatorURL": "http://prometheus-k8s-0:9090/graph?g0.expr=%28kube_statefulset_status_replicas_ready%7Bjob%3D%22kube-state-metrics%22%7D+%21%3D+kube_statefulset_status_replicas%7Bjob%3D%22kube-state-metrics%22%7D%29+and+%28changes%28kube_statefulset_status_replicas_updated%7Bjob%3D%22kube-state-metrics%22%7D%5B5m%5D%29+%3D%3D+0%29\u0026g0.tab=1",		"fingerprint": "1b3a1aba94e2a02f"	}],	"groupLabels": {		"alertname": "KubeStatefulSetReplicasMismatch"	},	"commonLabels": {		"alertname": "KubeStatefulSetReplicasMismatch",		"instance": "172.29.33.79:8443",		"job": "kube-state-metrics",		"namespace": "default",		"prometheus": "monitoring/k8s",		"severity": "warning",		"statefulset": "rd"	},	"commonAnnotations": {		"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",		"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"	},	"externalURL": "http://alertmanager-main-0:9093",	"version": "4",	"groupKey": "{}:{alertname=\"KubeStatefulSetReplicasMismatch\"}",	"truncatedAlerts": 0}
2021/04/21 17:36:29.581 [E] [telegram.go:28]  [1618997768564016800] [tg] Post "https://api.telegram.org/botxxxxx/getMe": dial tcp 202.160.130.145:443: connectex: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond.
2021/04/21 17:36:30.840 [C] [panic.go:965]  the request url is  /prometheusalert
2021/04/21 17:36:30.841 [C] [panic.go:965]  Handler crashed with error runtime error: invalid memory address or nil pointer dereference
2021/04/21 17:36:30.842 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/panic.go:965
2021/04/21 17:36:30.843 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/panic.go:212
2021/04/21 17:36:30.844 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/signal_windows.go:239
2021/04/21 17:36:30.846 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/go-telegram-bot-api/telegram-bot-api/v5/bot.go:100
2021/04/21 17:36:30.846 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/go-telegram-bot-api/telegram-bot-api/v5/bot.go:319
2021/04/21 17:36:30.847 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/go-telegram-bot-api/telegram-bot-api/v5/bot.go:326
2021/04/21 17:36:30.850 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/controllers/telegram.go:33
2021/04/21 17:36:30.861 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/controllers/prometheusalert.go:125
2021/04/21 17:36:30.862 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/controllers/prometheusalert.go:57
2021/04/21 17:36:30.867 [C] [panic.go:965]  C:/Program Files/Go/src/reflect/value.go:476
2021/04/21 17:36:30.868 [C] [panic.go:965]  C:/Program Files/Go/src/reflect/value.go:337
2021/04/21 17:36:30.869 [C] [panic.go:965]  D:/code/golang/src/PrometheusAlert/vendor/github.com/astaxie/beego/router.go:853
2021/04/21 17:36:30.870 [C] [panic.go:965]  C:/Program Files/Go/src/net/http/server.go:2887
2021/04/21 17:36:30.876 [C] [panic.go:965]  C:/Program Files/Go/src/net/http/server.go:1952
2021/04/21 17:36:30.877 [C] [panic.go:965]  C:/Program Files/Go/src/runtime/asm_amd64.s:1371
2021/04/21 17:36:30.881 [server.go:3137]  [HTTP] http: superfluous response.WriteHeader call from github.com/astaxie/beego/context.(*Response).WriteHeader (context.go:230)
2021/04/21 17:37:09.243 [D] [value.go:476]  [1618997829243123800] {	"receiver": "webhook",	"status": "firing",	"alerts": [{		"status": "firing",		"labels": {			"alertname": "KubeStatefulSetReplicasMismatch",			"instance": "172.29.33.79:8443",			"job": "kube-state-metrics",			"namespace": "default",			"prometheus": "monitoring/k8s",			"severity": "warning",			"statefulset": "rd"		},		"annotations": {			"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",			"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"		},		"startsAt": "2021-04-02T09:00:05.095800493Z",		"endsAt": "0001-01-01T00:00:00Z",		"generatorURL": "http://prometheus-k8s-0:9090/graph?g0.expr=%28kube_statefulset_status_replicas_ready%7Bjob%3D%22kube-state-metrics%22%7D+%21%3D+kube_statefulset_status_replicas%7Bjob%3D%22kube-state-metrics%22%7D%29+and+%28changes%28kube_statefulset_status_replicas_updated%7Bjob%3D%22kube-state-metrics%22%7D%5B5m%5D%29+%3D%3D+0%29\u0026g0.tab=1",		"fingerprint": "1b3a1aba94e2a02f"	}],	"groupLabels": {		"alertname": "KubeStatefulSetReplicasMismatch"	},	"commonLabels": {		"alertname": "KubeStatefulSetReplicasMismatch",		"instance": "172.29.33.79:8443",		"job": "kube-state-metrics",		"namespace": "default",		"prometheus": "monitoring/k8s",		"severity": "warning",		"statefulset": "rd"	},	"commonAnnotations": {		"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",		"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"	},	"externalURL": "http://alertmanager-main-0:9093",	"version": "4",	"groupKey": "{}:{alertname=\"KubeStatefulSetReplicasMismatch\"}",	"truncatedAlerts": 0}
2021/04/21 17:37:09.246 [I] [prometheusalert.go:76]  [1618997829243123800] [weixin] {"msgtype":"markdown","markdown":{"content":"\r\n\r\n [PrometheusÂëäË≠¶‰ø°ÊÅØ](http://prometheus-k8s-0:9090/graph?g0.expr=%28kube_statefulset_status_replicas_ready%7Bjob%3D%22kube-state-metrics%22%7D+%21%3D+kube_statefulset_status_replicas%7Bjob%3D%22kube-state-metrics%22%7D%29+and+%28changes%28kube_statefulset_status_replicas_updated%7Bjob%3D%22kube-state-metrics%22%7D%5B5m%5D%29+%3D%3D+0%29\u0026g0.tab=1)\r\n [KubeStatefulSetReplicasMismatch](http://alertmanager-main-0:9093)\r\n## ÂëäË≠¶Á∫ßÂà´Ôºö\u003cno value\u003e\r\n## ÂºÄÂßãÊó∂Èó¥Ôºö2021-04-02 17:00:05\r\n## ÁªìÊùüÊó∂Èó¥Ôºö0001-01-01 08:00:00\r\n## ÊïÖÈöú‰∏ªÊú∫IPÔºö172.29.33.79:8443\r\n# \u003cno value\u003e\r\n\r\n"}}

2021/04/21 17:37:09.312 [I] [prometheusalert.go:76]  [1618997829243123800] [weixin] {"msg":"Êìç‰ΩúÊàêÂäü","code":200}
2021/04/21 17:37:09.312 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    70.2085ms|   match|[46m POST    [0m /prometheusalert   r:/prometheusalert
2021/04/21 17:37:12.172 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    13.4375ms|   match|[46m POST    [0m /template/addtpl   r:/template/addtpl
2021/04/21 17:37:14.783 [D] [value.go:476]  [1618997834783298800] {	"receiver": "webhook",	"status": "firing",	"alerts": [{		"status": "firing",		"labels": {			"alertname": "KubeStatefulSetReplicasMismatch",			"instance": "172.29.33.79:8443",			"job": "kube-state-metrics",			"namespace": "default",			"prometheus": "monitoring/k8s",			"severity": "warning",			"statefulset": "rd"		},		"annotations": {			"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",			"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"		},		"startsAt": "2021-04-02T09:00:05.095800493Z",		"endsAt": "0001-01-01T00:00:00Z",		"generatorURL": "http://prometheus-k8s-0:9090/graph?g0.expr=%28kube_statefulset_status_replicas_ready%7Bjob%3D%22kube-state-metrics%22%7D+%21%3D+kube_statefulset_status_replicas%7Bjob%3D%22kube-state-metrics%22%7D%29+and+%28changes%28kube_statefulset_status_replicas_updated%7Bjob%3D%22kube-state-metrics%22%7D%5B5m%5D%29+%3D%3D+0%29\u0026g0.tab=1",		"fingerprint": "1b3a1aba94e2a02f"	}],	"groupLabels": {		"alertname": "KubeStatefulSetReplicasMismatch"	},	"commonLabels": {		"alertname": "KubeStatefulSetReplicasMismatch",		"instance": "172.29.33.79:8443",		"job": "kube-state-metrics",		"namespace": "default",		"prometheus": "monitoring/k8s",		"severity": "warning",		"statefulset": "rd"	},	"commonAnnotations": {		"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",		"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"	},	"externalURL": "http://alertmanager-main-0:9093",	"version": "4",	"groupKey": "{}:{alertname=\"KubeStatefulSetReplicasMismatch\"}",	"truncatedAlerts": 0}
2021/04/21 17:37:14.785 [I] [prometheusalert.go:76]  [1618997834783298800] [weixin] {"msgtype":"markdown","markdown":{"content":"\r\n\r\n [PrometheusÂëäË≠¶‰ø°ÊÅØ](http://prometheus-k8s-0:9090/graph?g0.expr=%28kube_statefulset_status_replicas_ready%7Bjob%3D%22kube-state-metrics%22%7D+%21%3D+kube_statefulset_status_replicas%7Bjob%3D%22kube-state-metrics%22%7D%29+and+%28changes%28kube_statefulset_status_replicas_updated%7Bjob%3D%22kube-state-metrics%22%7D%5B5m%5D%29+%3D%3D+0%29\u0026g0.tab=1)\r\n [KubeStatefulSetReplicasMismatch](http://alertmanager-main-0:9093)\r\n## ÂëäË≠¶Á∫ßÂà´Ôºö\u003cno value\u003e\r\n## ÂºÄÂßãÊó∂Èó¥Ôºö2021-04-02 17:00:05\r\n## ÁªìÊùüÊó∂Èó¥Ôºö0001-01-01 08:00:00\r\n## ÊïÖÈöú‰∏ªÊú∫IPÔºö172.29.33.79:8443\r\n# \u003cno value\u003e\r\n\r\n"}}

2021/04/21 17:37:14.805 [I] [prometheusalert.go:76]  [1618997834783298800] [weixin] {"msg":"Êìç‰ΩúÊàêÂäü","code":200}
2021/04/21 17:37:14.806 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    27.2495ms|   match|[46m POST    [0m /prometheusalert   r:/prometheusalert
2021/04/21 17:38:16.972 [I] [asm_amd64.s:1371]  http server Running on http://:8080
2021/04/21 17:38:25.076 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|     18.336ms|   match|[46m POST    [0m /template/addtpl   r:/template/addtpl
2021/04/21 17:38:44.897 [D] [value.go:476]  [1618997924897118300] {	"receiver": "webhook",	"status": "firing",	"alerts": [{		"status": "firing",		"labels": {			"alertname": "KubeStatefulSetReplicasMismatch",			"instance": "172.29.33.79:8443",			"job": "kube-state-metrics",			"namespace": "default",			"prometheus": "monitoring/k8s",			"severity": "warning",			"statefulset": "rd"		},		"annotations": {			"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",			"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"		},		"startsAt": "2021-04-02T09:00:05.095800493Z",		"endsAt": "0001-01-01T00:00:00Z",		"generatorURL": "http://prometheus-k8s-0:9090/graph?g0.expr=%28kube_statefulset_status_replicas_ready%7Bjob%3D%22kube-state-metrics%22%7D+%21%3D+kube_statefulset_status_replicas%7Bjob%3D%22kube-state-metrics%22%7D%29+and+%28changes%28kube_statefulset_status_replicas_updated%7Bjob%3D%22kube-state-metrics%22%7D%5B5m%5D%29+%3D%3D+0%29\u0026g0.tab=1",		"fingerprint": "1b3a1aba94e2a02f"	}],	"groupLabels": {		"alertname": "KubeStatefulSetReplicasMismatch"	},	"commonLabels": {		"alertname": "KubeStatefulSetReplicasMismatch",		"instance": "172.29.33.79:8443",		"job": "kube-state-metrics",		"namespace": "default",		"prometheus": "monitoring/k8s",		"severity": "warning",		"statefulset": "rd"	},	"commonAnnotations": {		"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",		"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"	},	"externalURL": "http://alertmanager-main-0:9093",	"version": "4",	"groupKey": "{}:{alertname=\"KubeStatefulSetReplicasMismatch\"}",	"truncatedAlerts": 0}
2021/04/21 17:38:44.899 [I] [prometheusalert.go:76]  [1618997924897118300] [weixin] {"msgtype":"markdown","markdown":{"content":"\r\n\r\n [PrometheusÂëäË≠¶‰ø°ÊÅØ](http://prometheus-k8s-0:9090/graph?g0.expr=%28kube_statefulset_status_replicas_ready%7Bjob%3D%22kube-state-metrics%22%7D+%21%3D+kube_statefulset_status_replicas%7Bjob%3D%22kube-state-metrics%22%7D%29+and+%28changes%28kube_statefulset_status_replicas_updated%7Bjob%3D%22kube-state-metrics%22%7D%5B5m%5D%29+%3D%3D+0%29\u0026g0.tab=1)\r\n [KubeStatefulSetReplicasMismatch](http://alertmanager-main-0:9093)\r\n## ÂëäË≠¶Á∫ßÂà´Ôºö\u003cno value\u003e\r\n## ÂºÄÂßãÊó∂Èó¥Ôºö2021-04-02 17:00:05\r\n## ÁªìÊùüÊó∂Èó¥Ôºö0001-01-01 08:00:00\r\n## ÊïÖÈöú‰∏ªÊú∫IPÔºö172.29.33.79:8443\r\n# \u003cno value\u003e\r\n\r\n"}}

2021/04/21 17:38:44.919 [I] [prometheusalert.go:76]  [1618997924897118300] [weixin] {"msg":"Êìç‰ΩúÊàêÂäü","code":200}
2021/04/21 17:38:44.921 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    24.8589ms|   match|[46m POST    [0m /prometheusalert   r:/prometheusalert
2021/04/21 17:39:17.802 [D] [value.go:476]  [1618997957802224400] {	"receiver": "webhook",	"status": "firing",	"alerts": [{		"status": "firing",		"labels": {			"alertname": "KubeStatefulSetReplicasMismatch",			"instance": "172.29.33.79:8443",			"job": "kube-state-metrics",			"namespace": "default",			"prometheus": "monitoring/k8s",			"severity": "warning",			"statefulset": "rd"		},		"annotations": {			"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",			"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"		},		"startsAt": "2021-04-02T09:00:05.095800493Z",		"endsAt": "0001-01-01T00:00:00Z",		"generatorURL": "http://prometheus-k8s-0:9090/graph?g0.expr=%28kube_statefulset_status_replicas_ready%7Bjob%3D%22kube-state-metrics%22%7D+%21%3D+kube_statefulset_status_replicas%7Bjob%3D%22kube-state-metrics%22%7D%29+and+%28changes%28kube_statefulset_status_replicas_updated%7Bjob%3D%22kube-state-metrics%22%7D%5B5m%5D%29+%3D%3D+0%29\u0026g0.tab=1",		"fingerprint": "1b3a1aba94e2a02f"	}],	"groupLabels": {		"alertname": "KubeStatefulSetReplicasMismatch"	},	"commonLabels": {		"alertname": "KubeStatefulSetReplicasMismatch",		"instance": "172.29.33.79:8443",		"job": "kube-state-metrics",		"namespace": "default",		"prometheus": "monitoring/k8s",		"severity": "warning",		"statefulset": "rd"	},	"commonAnnotations": {		"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",		"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"	},	"externalURL": "http://alertmanager-main-0:9093",	"version": "4",	"groupKey": "{}:{alertname=\"KubeStatefulSetReplicasMismatch\"}",	"truncatedAlerts": 0}
2021/04/21 17:39:22.021 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|  12.5011725s|   match|[46m POST    [0m /template/addtpl   r:/template/addtpl
2021/04/21 17:39:22.023 [I] [feishu.go:32]  [1618997957802224400] [feishu] {"title":"PrometheusAlertÂëäË≠¶Ê∂àÊÅØ","text":"\r\n\r\n [PrometheusÂëäË≠¶‰ø°ÊÅØ](http://prometheus-k8s-0:9090/graph?g0.expr=%28kube_statefulset_status_replicas_ready%7Bjob%3D%22kube-state-metrics%22%7D+%21%3D+kube_statefulset_status_replicas%7Bjob%3D%22kube-state-metrics%22%7D%29+and+%28changes%28kube_statefulset_status_replicas_updated%7Bjob%3D%22kube-state-metrics%22%7D%5B5m%5D%29+%3D%3D+0%29\u0026g0.tab=1)\r\n [KubeStatefulSetReplicasMismatch](http://alertmanager-main-0:9093)\r\n## ÂëäË≠¶Á∫ßÂà´Ôºö\u003cno value\u003e\r\n## ÂºÄÂßãÊó∂Èó¥Ôºö2021-04-02 17:00:05\r\n## ÁªìÊùüÊó∂Èó¥Ôºö0001-01-01 08:00:00\r\n## ÊïÖÈöú‰∏ªÊú∫IPÔºö172.29.33.79:8443\r\n# \u003cno value\u003e\r\n\r\n"}

2021/04/21 17:39:22.049 [I] [feishu.go:32]  [1618997957802224400] [feishu] {"msg":"Êìç‰ΩúÊàêÂäü","code":200}
2021/04/21 17:39:22.051 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|   4.2487802s|   match|[46m POST    [0m /prometheusalert   r:/prometheusalert
2021/04/21 17:39:25.004 [I] [asm_amd64.s:1371]  http server Running on http://:8080
2021/04/21 17:39:29.204 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    12.1058ms|   match|[46m POST    [0m /template/addtpl   r:/template/addtpl
2021/04/21 17:39:31.595 [D] [value.go:476]  [1618997971595055200] {	"receiver": "webhook",	"status": "firing",	"alerts": [{		"status": "firing",		"labels": {			"alertname": "KubeStatefulSetReplicasMismatch",			"instance": "172.29.33.79:8443",			"job": "kube-state-metrics",			"namespace": "default",			"prometheus": "monitoring/k8s",			"severity": "warning",			"statefulset": "rd"		},		"annotations": {			"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",			"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"		},		"startsAt": "2021-04-02T09:00:05.095800493Z",		"endsAt": "0001-01-01T00:00:00Z",		"generatorURL": "http://prometheus-k8s-0:9090/graph?g0.expr=%28kube_statefulset_status_replicas_ready%7Bjob%3D%22kube-state-metrics%22%7D+%21%3D+kube_statefulset_status_replicas%7Bjob%3D%22kube-state-metrics%22%7D%29+and+%28changes%28kube_statefulset_status_replicas_updated%7Bjob%3D%22kube-state-metrics%22%7D%5B5m%5D%29+%3D%3D+0%29\u0026g0.tab=1",		"fingerprint": "1b3a1aba94e2a02f"	}],	"groupLabels": {		"alertname": "KubeStatefulSetReplicasMismatch"	},	"commonLabels": {		"alertname": "KubeStatefulSetReplicasMismatch",		"instance": "172.29.33.79:8443",		"job": "kube-state-metrics",		"namespace": "default",		"prometheus": "monitoring/k8s",		"severity": "warning",		"statefulset": "rd"	},	"commonAnnotations": {		"message": "StatefulSet default/rd has not matched the expected number of replicas for longer than 15 minutes.",		"runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"	},	"externalURL": "http://alertmanager-main-0:9093",	"version": "4",	"groupKey": "{}:{alertname=\"KubeStatefulSetReplicasMismatch\"}",	"truncatedAlerts": 0}
2021/04/21 17:39:31.598 [I] [feishu.go:32]  [1618997971595055200] [feishu] {"title":"PrometheusAlertÂëäË≠¶Ê∂àÊÅØ","text":"\r\n\r\n [PrometheusÂëäË≠¶‰ø°ÊÅØ](http://prometheus-k8s-0:9090/graph?g0.expr=%28kube_statefulset_status_replicas_ready%7Bjob%3D%22kube-state-metrics%22%7D+%21%3D+kube_statefulset_status_replicas%7Bjob%3D%22kube-state-metrics%22%7D%29+and+%28changes%28kube_statefulset_status_replicas_updated%7Bjob%3D%22kube-state-metrics%22%7D%5B5m%5D%29+%3D%3D+0%29\u0026g0.tab=1)\r\n [KubeStatefulSetReplicasMismatch](http://alertmanager-main-0:9093)\r\n## ÂëäË≠¶Á∫ßÂà´Ôºö\u003cno value\u003e\r\n## ÂºÄÂßãÊó∂Èó¥Ôºö2021-04-02 17:00:05\r\n## ÁªìÊùüÊó∂Èó¥Ôºö0001-01-01 08:00:00\r\n## ÊïÖÈöú‰∏ªÊú∫IPÔºö172.29.33.79:8443\r\n# \u003cno value\u003e\r\n\r\n"}

2021/04/21 17:39:31.617 [I] [feishu.go:32]  [1618997971595055200] [feishu] {"msg":"Êìç‰ΩúÊàêÂäü","code":200}
2021/04/21 17:39:31.618 [D] [server.go:2887]  |      127.0.0.1|[42m 200 [0m|    23.8883ms|   match|[46m POST    [0m /prometheusalert   r:/prometheusalert
